slug: terraform-build-your-own-provider
id: h1tpybfmtmve
type: track
title: Build Your Own Terraform Provider
teaser: Learn how to create your own Terraform Provider to perform CRUD operations.
description: |-
  In this track, you will create a Terraform provider to interact with a fictional coffee-shop application, HashiCups.
  In the process, you will learn how providers map target APIs to Terraform in order to create, read, update, and delete
  resources.
icon: https://storage.googleapis.com/instruqt-frontend/assets/hashicorp/tracks/terraform.png
tags:
- terraform
owner: hashicorp
developers:
- neil@hashicorp.com
private: true
published: false
challenges:
- slug: setup-and-implement-read
  id: pxpflxfcohzc
  type: challenge
  title: Setup and Implement Read
  teaser: TODO
  assignment: |-
    *Set up your development environment*

    The Terraform HashiCups Provider repository has been cloned for you. It will serve as the boilerplate for your
    provider workspace. Change into the cloned repository.

    The HashiCups provider requires an instance of HashiCups. This has been started for you using `docker-compose` and
    the service is run on port `:19090`. Confirm the service is running.

    ```
    curl localhost:19090/health
    ```

    ```
    curl -X POST localhost:19090/signup -d '{"username":"education", "password":"test123"}' | jq
    ```

    *Explore your development environment*


    Run the `go mod init` command to define this directory as the root of a module. Then, run `go mod vendor` to
    create a `vendor` directory that contains all the provider's dependencies.

    ```
    cd /root/github.com/hashicorp/terraform-provider-hashicups
    go mod init terraform-provider-hashicups
    go mod vendor
    ```

    Next, build the provider using the Makefile.

    ```
    make build
    ```

    This runs the `go build -o terraform-provider-hashicups` command. Terraform searches for plugins in the format of
    `terraform-<TYPE>-<NAME>`. In the case above, the plugin is of type "provider" and of name "hashicups".

    To verify things are working correctly, execute the recently created binary.

    ```
    ./terraform-provider-hashicups
    ```

    You should see output like the below.

    ```
    This binary is a plugin. These are not meant to be executed directly.
    Please execute the program that consumes these plugins, which will
    load any plugins automatically
    ```

    *Define the coffees data source*

    Now that you have created the provider, add the coffees data resource. The coffees data source will pull information
    on all coffees served by HashiCups.

    Create a new file named `data_source_coffee.go` in the `hashicups` directory and add the following code snippet. As a
    general convention, Terraform providers put each data source in their own file, named after the resource, prefixed
    with data_source_.

    The libraries imported here will be used in `dataSourceCoffeesRead`.

    ```
    package hashicups

    import (
      "context"
      "encoding/json"
      "fmt"
      "net/http"
      "strconv"
      "time"

      "github.com/hashicorp/terraform-plugin-sdk/v2/diag"
      "github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
    )

    func dataSourceCoffees() *schema.Resource {
      return &schema.Resource{
        ReadContext: dataSourceCoffeesRead,
        Schema: map[string]*schema.Schema{},
      }
    }
    ```

    *Define the coffees schema*

    ```
    curl localhost:19090/coffees
    ```

    Since the response returns a list of coffees, the coffees schema should reflect that. Update your coffees data
    source's schema with the following code snippet.

    ```
    Schema: map[string]*schema.Schema{
      "coffees": &schema.Schema{
        Type:     schema.TypeList,
        Computed: true,
        Elem: &schema.Resource{
          Schema: map[string]*schema.Schema{
            "id": &schema.Schema{
              Type:     schema.TypeInt,
              Computed: true,
            },
            "name": &schema.Schema{
              Type:     schema.TypeString,
              Computed: true,
            },
            "teaser": &schema.Schema{
              Type:     schema.TypeString,
              Computed: true,
            },
            "description": &schema.Schema{
              Type:     schema.TypeString,
              Computed: true,
            },
            "price": &schema.Schema{
              Type:     schema.TypeInt,
              Computed: true,
            },
            "image": &schema.Schema{
              Type:     schema.TypeString,
              Computed: true,
            },
            "ingredients": &schema.Schema{
              Type:     schema.TypeList,
              Computed: true,
              Elem: &schema.Resource{
                Schema: map[string]*schema.Schema{
                  "ingredient_id": &schema.Schema{
                    Type:     schema.TypeInt,
                    Computed: true,
                  },
                },
              },
            },
          },
        },
      },
    },
    ```

    Format your code.

    ```
    go fmt ./...
    ```

    Notice that the coffees schema is a `schema.TypeList` of coffee (`schema.Resource`).

    The coffee resource's properties should map to their respective values in the JSON response. In the above example
    response:

    - The coffee's `id` is `1`, a `schema.TypeInt`.
    - The coffee's `name` is `"Packer Spiced Latte"`, a `schema.TypeString`.
    - The coffee ingredients is an array of ingredient objects, a `schema.TypeList` with elements `map[string]*schema.Schema{}`.

    You can use various [schema types](https://www.terraform.io/docs/extend/schemas/schema-types.html) to define complex
    data models. You will implement a complex read in the later challenges.

    *Implement read*

    Now that you defined the coffees schema, you can implement the `dataSourceCoffeesRead` function.

    Add the following read function to your `hashicups/data_source_coffee.go` file.

    ```
    func dataSourceCoffeesRead(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
      client := &http.Client{Timeout: 10 * time.Second}

      // Warning or errors can be collected in a slice type
      var diags diag.Diagnostics

      req, err := http.NewRequest("GET", fmt.Sprintf("%s/coffees", "http://localhost:19090"), nil)
      if err != nil {
        return diag.FromErr(err)
      }

      r, err := client.Do(req)
      if err != nil {
        return diag.FromErr(err)
      }
      defer r.Body.Close()

      coffees := make([]map[string]interface{}, 0)
      err = json.NewDecoder(r.Body).Decode(&coffees)
      if err != nil {
        return diag.FromErr(err)
      }

      if err := d.Set("coffees", coffees); err != nil {
        return diag.FromErr(err)
      }

      // always run
      d.SetId(strconv.FormatInt(time.Now().Unix(), 10))

      return diags
    }
    ```

    Format your code.

    ```
    go fmt ./...
    ```

    This function creates a new GET request to `localhost:19090/coffees`. Then, it decodes the response into a
    `[]map[string]interface{}`. The `d.Set("coffees", coffees)` function sets the response body (list of coffees
    object) to Terraform coffees data source, assigning each value to its respective schema position. Finally, it uses
    `SetID` to set the resource ID.

    Notice that this function returns a diag.Diagnostics type, which can return multiple errors and warnings to
    Terraform, giving users more robust error and warning messages. You can use the `diag.FromErr()` helper function to
    convert a Go error to a `diag.Diagnostics type`. You will implement this in a later challenge.


    _Tip: This function doesn't use an API client library to explicitly show the steps involved. The HashiCups client
    library is used to abstract CRUD functionality in other tutorials._

    The existence of a non-blank ID tells Terraform that a resource was created. This ID can be any string value, but
    should be a value that Terraform can use to read the resource again. Since this data resource doesn't have a unique
    ID, you set the ID to the current UNIX time, which will force this resource to refresh during every Terraform apply.

    When you create something in Terraform but delete it manually, Terraform should gracefully handle it. If the API
    returns an error when the resource doesn't exist, the read function should check to see if the resource is
    available first. If the resource isn't available, the function should set the ID to an empty string so Terraform
    "destroys" the resource in state. The following code snippet is an example of how this can be implemented; you do
    not need to add this to your configuration for this tutorial.

    ```
    if resourceDoesntExist {
      d.SetID("")
      return
    }
    ```

    *Add a coffees data source to provider*

    Now that you've defined your data source, you can add it to your provider.

    In your `hashicups/provider.go` file, add the coffees data source to the `DataSourcesMap`. The `DataSourcesMap`
    attribute takes a map of the data source name, `hashicups_coffees`, and the `*schema.Resource` defined in
    `hashicups/data_source_coffee.go`. Resources and data sources names must follow the `<provider>_<resource_name>`
    convention.

    Change your `DataSourcesMap` to contain our new data source.

    ```
      DataSourcesMap: map[string]*schema.Resource{
        "hashicups_coffees":     dataSourceCoffees(),
      },
    ```

    Format your code.

    ```
    go fmt ./...
    ```

    *Test the provider*

    Build the provider binary.

    ```
    cd /root/github.com/hashicorp/terraform-provider-hashicups
    make build
    ```

    Create the appropriate subdirectory within the user plugins directory for the HashiCups provider if it doesn't
    exist already.

    ```
    export OS_ARCH="$(go env GOHOSTOS)_$(go env GOHOSTARCH)"
    mkdir -p ~/.terraform.d/plugins/hashicorp.com/edu/hashicups/0.2/$OS_ARCH
    ```

    Next, move the binary to the appropriate subdirectory within your user plugins directory.

    ```
    mv terraform-provider-hashicups ~/.terraform.d/plugins/hashicorp.com/edu/hashicups/0.2/$OS_ARCH
    ```

    Navigate to the `terraform-provider-hashicups/examples` directory. This contains a sample Terraform configuration
    for the Terraform HashiCups provider.

    ```
    cd examples
    ```

    Finally, initialize your workspace to refresh your HashiCups provider, then apply. This should return the
    properties of "Packer Spice Latte" in your output.

    ```
    terraform init && terraform apply --auto-approve
    ```

    You should see output like the below.

    ```
    Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

    Outputs:

    psl = {
      "1" = {
        "description" = ""
        "id" = 1
        "image" = "/packer.png"
        "ingredients" = tolist([
          {
            "ingredient_id" = 1
          },
          {
            "ingredient_id" = 2
          },
          {
            "ingredient_id" = 4
          },
        ])
        "name" = "Packer Spiced Latte"
        "price" = 350
        "teaser" = "Packed with goodness to spice up your images"
      }
    }
    ```

    Congratulations! You created your first Terraform provider and data resource to reference information from an API
    in your Terraform configuration.
  notes:
  - type: text
    contents: |-
      In these tutorials, you will write a custom provider against the API of a fictional coffee-shop application called
      HashiCups using the Terraform Plugin SDKv2. Through the process, you will learn how to create data sources,
      authenticate the provider to the HashiCups client, and create resources with CRUD functionality.
  - type: text
    contents: |-
      - Set up your development environment.
      - Define the coffees data source.
      - Define the coffees schema.
      - Implement read.
      - Add coffees data source to the provider schema.
  tabs:
  - title: Text Editor
    type: code
    hostname: workstation
    path: /root/github.com/hashicorp/terraform-provider-hashicups
  - title: Terminal
    type: terminal
    hostname: workstation
  difficulty: basic
  timelimit: 1800
checksum: "7236237399288813528"
